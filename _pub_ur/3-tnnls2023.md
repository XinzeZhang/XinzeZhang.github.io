---
layout: article
title: 'Reinforced Decoder: Towards Training Recurrent Neural Networks for Time Series Forecasting'
permalink: /under_review/tnnls2023.html
key: ur-tnnls2023
---
Qi Sima, Xinze Zhang, Yukun Bao, Siyue Yang, and Liang Shen

<!--more-->

### Abstract

<div style="text-align: justify"   markdown='1'>
Recurrent neural network-based sequence-to-sequence models have been extensively applied and proven to be effective in multi-step-ahead time series prediction, where the decoder is trained to produce the sequence of target predictions given some inputs, such as recent one-step-ahead predictions or ground-truth values. However, the former is prone to rapid error amplification due to the use of its own predictions from previous steps, while the latter leads to the exposure bias problem because the ground-truth values are not available at the testing stage. In this regard, this study proposes a novel training approach based on reinforcement learning called reinforced decoder, which employs auxiliary models to generate inputs for the decoder and uses reinforcement learning algorithms to adaptively select the optimal inputs to improve the accuracy and robustness of multi-step-ahead time series prediction. Comprehensive experiments implemented on multiple datasets demonstrated the effectiveness of the proposed Method.

</div>